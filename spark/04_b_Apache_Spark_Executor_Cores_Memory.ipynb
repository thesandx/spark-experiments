{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61021275-0025-4f5d-afb6-ecd839bfef05",
   "metadata": {},
   "source": [
    "# Apache Spark Executor Cores & Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42617f75-4011-4b8d-8987-2890d405fa7b",
   "metadata": {},
   "source": [
    "Here are the notes on Apache Spark Executor Cores & Memory from the video transcript:\n",
    "\n",
    "*   If CPU and memory resources are not correctly allocated, Spark jobs may take a long time to complete.\n",
    "\n",
    "*   **Executor Tuning** involves deciding the number of executors to create, the amount of memory, and the number of cores to allocate to those executors.\n",
    "\n",
    "*   To decide the number of executors, cores, and memory to assign, consider some examples.\n",
    "\n",
    "*   **Cluster Configuration Example**: Let's say you have five nodes (machines), each with 12 cores and 48 GB of RAM. The question is how to decide the number of executors, cores per executor, and memory per executor.\n",
    "\n",
    "*   There are generally three options to consider when deciding on executors: **thin executors, fat executors, and optimally sized executors**.\n",
    "\n",
    "*   **Fat Executors**\n",
    "    *   Occupy a large portion of the resources on a node.\n",
    "    *   Calculation: First, leave out one core and 1 GB of RAM for the operating system and other processes.\n",
    "    *   If a machine has 12 cores and 48 GB of RAM, you will have 11 cores and 47 GB of RAM available per node.\n",
    "    *   One fat executor will take all 11 cores and 47 GB of RAM.\n",
    "    *   One node will have one executor.\n",
    "    *   If the cluster has five nodes, you will have five executors.\n",
    "    *   The number of executors is five, executor cores is 11, and executor memory is 47 GB.\n",
    "    *   Each of the five executors will have 11 cores and 47 GB of RAM.\n",
    "    *   Advantages:\n",
    "        *   Increased task level parallelism. With a lot of cores, fat executors can run many tasks together.\n",
    "        *   Can load data which requires significant amounts of memory.\n",
    "        *   Managing a lot of executors is not a concern because one node has one or minimal executors.\n",
    "        *   Enhanced data locality. The executor can fit a lot of partitions in its memory. Reduces network traffic, improves application speed.\n",
    "    *   Disadvantages:\n",
    "        *   If the executor is not fully utilized, resources will sit idle.\n",
    "        *   Fault tolerance. If an executor fails, a large amount of computation will be lost, reducing application reliability.\n",
    "        *   For those using HDFS, using more than five cores can cause garbage collection, which pauses the program and takes a performance toll.\n",
    "*   **Thin Executors**\n",
    "    *   Occupy minimal resources from the node.\n",
    "    *   Calculation:\n",
    "        *   Again, leaving out one core and 1 GB of RAM per node, you are left with 11 cores and 47 GB of RAM.\n",
    "        *   Give one core to one executor. Therefore, one node will have 11 executors.\n",
    "        *   With 11 executors in total and 47 GB of RAM on a node, each executor will have close to 4 GB of RAM.\n",
    "        *   One executor will contain one core and 4 GB of RAM.\n",
    "        *   One node has 11 executors, and with five nodes, you will end up with 55 executors.\n",
    "        *   The number of executors will be 55, the executor code will be one, and the executor memory will be close to 4 GB.\n",
    "    *   Advantages:\n",
    "        *   Executor level parallelism.\n",
    "        *   Fault tolerance. If an executor is lost, it is easy to recompute what has already been done.\n",
    "    *   Disadvantages:\n",
    "        *   High network traffic. The data it needs might not be fully present on the executor, so it needs to move data across the cluster.\n",
    "        *   Reduced data locality. Because each executor has a small amount of memory, the number of partitions that are local will be small.\n",
    "*   **Optimally Sized Executors**\n",
    "    *   To size or create an optimal executor, keep in mind the following rules:\n",
    "        1.  Leave out one core and 1 GB of RAM for Hadoop, YARN, and operating system processes.\n",
    "        2.  Leave out one executor or one core and 1 GB of RAM for the YARN application master, which negotiates resources to the resource manager. The application master generally works well with one core and 1 GB of RAM. If the executor is small, subtract one executor when you define the num executors. However, this may not be suitable for cases where you have a fat executor.\n",
    "        3.  Have three to five tasks per executor. It is a general good practice to have three to five cores per executor because HDFS throughput deteriorates if you have more than five cores per executor, which leads to a lot of garbage collection.\n",
    "        4.  When you define your executor memory, this should exclude the memory overhead, which is used for internal system processes.\n",
    "    *   **Example**:\n",
    "        *   Five node cluster, each with 12 cores and 48 GB of RAM.\n",
    "        *   Leave out one core and 1 GB of RAM per node for Hadoop daemons and other operating system processes.\n",
    "        *   Per node, after subtracting, you are left with 11 cores and 47 GB of RAM.\n",
    "        *   Calculate the total memory and cores you have in the cluster.\n",
    "            *   The total memory is 47 GB * 5 = 235 GB.\n",
    "            *   The total cores is 11 * 5 = 55 cores.\n",
    "        *   Subtract out one core and 1 GB of RAM for the application master.\n",
    "            *   235 GB - 1 GB = 234 GB\n",
    "            *   55 cores - 1 core = 54 cores\n",
    "        *   Assign five cores for each executor.\n",
    "            *   The total executors is the total cores divided by the cores per executor.\n",
    "            *   54 cores / 5 cores is close to 10 executors.\n",
    "        *   To find out the memory per executor, take the total memory, 234 GB, and divide it by the number of executors, 10, which gives you close to 23.4 GB.\n",
    "        *   Subtract the overhead memory from the executor memory to get the actual executor memory. The calculation for overhead memory is the maximum of 384 MB or 10% of whatever executor memory we have.\n",
    "            *   23 GB - max(384 MB, 10% of 23 GB)\n",
    "            *   23 GB - max(384 MB, 2.3 GB)\n",
    "            *   23 GB - 2.3 GB = 20 GB\n",
    "        *   The number of executors is 10, the cores per executor is five cores, and the memory per executor is 20 GB.\n",
    "        *   It is important to focus on the memory per core.\n",
    "            *   With five cores and 20 GB of memory, one core will get 4 GB of memory.\n",
    "            *   One core can process one partition.\n",
    "            *   As long as a partition is less than or equal to 4 GB, the processing should happen seamlessly.\n",
    "        *   With data partitioned into sizes of 128 MB, this configuration is very good because each core can live up to 4 GB of data.\n",
    "    *   Benefits:\n",
    "        *   Maintains a balance between thin and fat executors.\n",
    "        *   Good configuration for good parallelism.\n",
    "        *   Avoid issues with HDFS throughput because we have assigned five cores, which should be good.\n",
    "        *   Data locality is preserved and enhanced because the amount of memory is 20 GB of RAM, so the number of partitions this executor can hold should be a good number.\n",
    "    *   **Example 2:**\n",
    "        *   Three nodes, each with 16 cores and 48 GB of RAM.\n",
    "            1.  Leave out one core and 1 GB of RAM per node.\n",
    "                *   You will be left with 15 cores and 47 GB of RAM per node.\n",
    "            2.  Calculate the total memory and total cores.\n",
    "                *   Total cores: 15 * 3 = 45 cores\n",
    "                *   Total memory: 47 * 3 = 141 GB\n",
    "            3.  Leave out 1 GB of RAM and one core for the application master.\n",
    "                *   45 cores - 1 core = 44 cores\n",
    "                *   141 GB - 1 GB = 140 GB\n",
    "            4.  Find out how many executors we want to create, the number of cores, and the memory.\n",
    "                *   Give four cores per executor.\n",
    "                    *   The number of executors is the total cores / core per executor, so 44 / 4 = 11 executors.\n",
    "                *   Total memory is 140 GB, and there are 11 executors, which is close to 12 GB.\n",
    "                *   Subtract out the memory overhead.\n",
    "                    *   The memory overhead is the maximum of 384 MB or 10% of executor memory.\n",
    "                    *   10% of 12 GB is 1.2 GB.\n",
    "                    *   Assume the overhead memory is 1 GB to make the calculation simple.\n",
    "                *   The actual memory is 12 GB - 1 GB = 11 GB.\n",
    "        *   The number of executors is 11, the executor cores is four, and the executor memory is 11 GB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1dd7ff-a451-4d2d-991c-3bae571707e6",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ead08f-510b-413b-85c0-1a0eac086ba3",
   "metadata": {},
   "source": [
    "## Apache Spark Executor Cores & Memory Allocation MCQs\n",
    "\n",
    "Here are some multiple-choice questions (MCQs) to help you revise the concepts of Apache Spark Executor Cores & Memory allocation based on the information from the video:\n",
    "\n",
    "**Question 1:** What is the primary goal of executor tuning in Apache Spark?\n",
    "* a) To minimize the number of executors\n",
    "* b) To optimally allocate CPU and memory resources for Spark jobs\n",
    "* c) To maximize the memory usage of the driver program\n",
    "* d) To reduce the amount of data processed\n",
    "\n",
    "**Question 2:** Which of the following is NOT a general type of executor configuration discussed in the video?\n",
    "* a) Thin Executors\n",
    "* b) Fat Executors\n",
    "* c) Medium Executors\n",
    "* d) Optimally Sized Executors\n",
    "\n",
    "**Question 3:** What is a characteristic of \"Fat Executors\"?\n",
    "* a) They occupy minimal resources from a node.\n",
    "* b) They are suitable for lightweight jobs.\n",
    "* c) They occupy a large portion of the resources on a node.\n",
    "* d) They enhance network traffic.\n",
    "\n",
    "**Question 4:** What is a key advantage of Fat Executors?\n",
    "* a) Increased task level parallelism\n",
    "* b) Lower memory requirements\n",
    "* c) Reduced data locality\n",
    "* d) Lower fault tolerance\n",
    "\n",
    "**Question 5:** What is a primary disadvantage of Fat Executors?\n",
    "* a) Low network traffic\n",
    "* b) Efficient resource utilization\n",
    "* c) Potential for resource wastage if not fully utilized\n",
    "* d) Enhanced data locality\n",
    "\n",
    "**Question 6:** What is a defining characteristic of \"Thin Executors\"?\n",
    "* a) They occupy a large portion of the resources on a node.\n",
    "* b) They are not fault-tolerant.\n",
    "* c) They occupy minimal resources from a node.\n",
    "* d) They are suitable for memory-intensive tasks.\n",
    "\n",
    "**Question 7:** What is an advantage of using Thin Executors?\n",
    "* a) Reduced network traffic\n",
    "* b) Better fault tolerance\n",
    "* c) Enhanced data locality\n",
    "* d) Ability to process large amounts of data in each executor\n",
    "\n",
    "**Question 8:** What is a key disadvantage of Thin Executors?\n",
    "* a) High fault tolerance\n",
    "* b) Efficient data locality\n",
    "* c) High network traffic\n",
    "* d) Limited parallelism\n",
    "\n",
    "**Question 9:** When sizing optimal executors, what resources should be reserved per node for the OS, YARN, and Hadoop daemons?\n",
    "* a) Leave out five cores and 5 GB of RAM\n",
    "* b) Leave out one core and 1 GB of RAM\n",
    "* c) Allocate all available resources\n",
    "* d) This is not necessary for optimal sizing.\n",
    "\n",
    "**Question 10:** According to the video, what is the general recommendation for the number of cores per executor to optimize HDFS throughput?\n",
    "* a) More than 10 cores\n",
    "* b) More than 7 cores\n",
    "* c) Three to five cores\n",
    "* d) Only one core\n",
    "\n",
    "**Question 11:** What is the purpose of the YARN application master?\n",
    "* a) To manage data locality\n",
    "* b) To execute tasks within executors\n",
    "* c) To negotiate resources with the resource manager\n",
    "* d) To monitor executor health\n",
    "\n",
    "**Question 12:** When calculating executor memory, what should be excluded from the total memory allocated?\n",
    "* a) Memory used by the OS\n",
    "* b) Memory used by YARN\n",
    "* c) Memory overhead for internal system processes\n",
    "* d) Memory used for caching data\n",
    "\n",
    "**Question 13:** If an executor has five cores and 20 GB of memory, how much memory is allocated per core?\n",
    "* a) 2 GB\n",
    "* b) 4 GB\n",
    "* c) 5 GB\n",
    "* d) 20 GB\n",
    "\n",
    "**Question 14:** Cluster configuration: 3 nodes, each with 16 cores and 48 GB RAM. After subtracting resources for OS and YARN daemons, how many cores are left per node?\n",
    "* a) 16 cores\n",
    "* b) 15 cores\n",
    "* c) 14 cores\n",
    "* d) 12 cores\n",
    "\n",
    "**Question 15:** In the above scenario, after also reserving resources for the application master, what are the total available cores in the cluster?\n",
    "* a) 40\n",
    "* b) 45\n",
    "* c) 44\n",
    "* d) 48\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3902c5a-534c-4170-b366-793bc01c4eb0",
   "metadata": {},
   "source": [
    "# Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127396d5-3def-48c8-961a-36f12c2f7ff8",
   "metadata": {},
   "source": [
    "Here are the answers to the multiple-choice questions (MCQs) with the correct option and a brief explanation, based on the video transcript:\n",
    "\n",
    "*   Question 1: What is the primary goal of executor tuning in Apache Spark?\n",
    "    *   b) **To optimally allocate CPU and memory resources for Spark jobs**.\n",
    "        *   Executor tuning focuses on correctly allocating CPU and memory resources.\n",
    "*   Question 2: Which of the following is NOT a general type of executor configuration discussed in the video?\n",
    "    *   c) **Medium Executors**.\n",
    "        *   The video discusses thin, fat, and optimally sized executors.\n",
    "*   Question 3: What is a characteristic of \"Fat Executors\"?\n",
    "    *   c) They **occupy a large portion of the resources on a node**.\n",
    "        *   Fat executors are defined as those that use a significant amount of resources on a node.\n",
    "*   Question 4: What is a key advantage of Fat Executors?\n",
    "    *   a) **Increased task level parallelism**.\n",
    "        *   Fat executors have many cores, enabling multiple tasks to run in parallel within the same executor.\n",
    "*   Question 5: What is a primary disadvantage of Fat Executors?\n",
    "    *   c) **Potential for resource wastage if not fully utilized**.\n",
    "        *   If a fat executor isn't fully utilized, the allocated resources may sit idle.\n",
    "*   Question 6: What is a defining characteristic of \"Thin Executors\"?\n",
    "    *   c) They **occupy minimal resources from a node**.\n",
    "        *   Thin executors use only a small amount of resources from the node.\n",
    "*   Question 7: What is an advantage of using Thin Executors?\n",
    "    *   b) **Better fault tolerance**.\n",
    "        *   Because thin executors process smaller amounts of data, the impact of an executor failure is reduced.\n",
    "*   Question 8: What is a key disadvantage of Thin Executors?\n",
    "    *   c) **High network traffic**.\n",
    "        *   Thin executors have small memories, potentially requiring data to be moved across the cluster, increasing network traffic.\n",
    "*   Question 9: When sizing optimal executors, what resources should be reserved per node for the OS, YARN, and Hadoop daemons?\n",
    "    *   b) **Leave out one core and 1 GB of RAM**.\n",
    "        *   It is recommended to leave out one core and 1 GB of RAM per node for these processes.\n",
    "*   Question 10: According to the video, what is the general recommendation for the number of cores per executor to optimize HDFS throughput?\n",
    "    *   c) **Three to five cores**.\n",
    "        *   The recommendation is to have three to five cores per executor to avoid garbage collection issues that negatively impact HDFS throughput.\n",
    "*   Question 11: What is the purpose of the YARN application master?\n",
    "    *   c) To **negotiate resources with the resource manager**.\n",
    "        *   The application master negotiates for resources from the resource manager.\n",
    "*   Question 12: When calculating executor memory, what should be excluded from the total memory allocated?\n",
    "    *   c) **Memory overhead for internal system processes**.\n",
    "        *   Executor memory should exclude the memory overhead used for internal system processes.\n",
    "*   Question 13: If an executor has five cores and 20 GB of memory, how much memory is allocated per core?\n",
    "    *   b) **4 GB**.\n",
    "        *   With 20 GB of memory for five cores, each core has 4 GB of memory (20/5 = 4).\n",
    "*   Question 14: Cluster configuration: 3 nodes, each with 16 cores and 48 GB RAM. After subtracting resources for OS and YARN daemons, how many cores are left per node?\n",
    "    *   b) **15 cores**.\n",
    "        *   After subtracting one core per node for OS and YARN, 15 cores remain (16 - 1 = 15).\n",
    "*   Question 15: In the above scenario, after also reserving resources for the application master, what are the total available cores in the cluster?\n",
    "    *   c) **44**.\n",
    "        *   With 15 cores per node across three nodes, there are 45 total cores. After subtracting one core for the application master, 44 cores are available (15 * 3 - 1 = 44).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed0873-afd7-45a6-8929-71c8ebf50d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
